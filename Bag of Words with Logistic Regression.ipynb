{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nikhil\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Case', 'Age', 'Text Details', 'Surgery - Yes OR No',\n",
       "       'word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "!pwd\n",
    "dataset = pd.read_csv('/Users/nikhil/pre_processed_patient_diagnostics.csv', encoding='ISO-8859-1');\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Surgery - Yes OR No'] = dataset['Surgery - Yes OR No'].astype(str) # taking the target column in seperate variable. we will add this to final data frame when pre processing is done\n",
    "data_desc = dataset[\"Text Details\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(data_desc)):\n",
    "    data_desc[i] = re.sub(\" \\d+\", \" \",data_desc[i]) # this will retain only the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "data_mat = bow.fit_transform(data_desc)\n",
    "dense = data_mat.todense()\n",
    "\n",
    "print(dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     abdomen  abdominal  abdominalback  ablation  abnormality  above  \\\n",
      "0          0          0              0         0            1      0   \n",
      "1          0          0              0         0            0      1   \n",
      "2          0          0              0         0            0      0   \n",
      "3          1          0              0         0            0      0   \n",
      "4          0          0              0         0            0      0   \n",
      "5          0          0              0         0            0      0   \n",
      "6          0          0              0         0            0      0   \n",
      "7          0          0              0         0            0      0   \n",
      "8          1          0              0         0            0      0   \n",
      "9          0          0              0         0            0      0   \n",
      "10         0          0              0         0            0      0   \n",
      "11         0          0              0         0            0      0   \n",
      "12         1          0              0         0            0      0   \n",
      "13         0          0              0         0            0      0   \n",
      "14         0          0              0         0            0      1   \n",
      "15         0          0              0         0            0      0   \n",
      "16         2          0              0         0            0      0   \n",
      "17         0          0              0         0            0      0   \n",
      "18         0          0              0         0            0      0   \n",
      "19         0          0              0         0            0      0   \n",
      "20         0          0              0         0            0      0   \n",
      "21         0          0              0         0            0      0   \n",
      "22         1          0              0         0            0      0   \n",
      "23         2          0              0         0            0      0   \n",
      "24         1          0              0         0            0      0   \n",
      "25         0          0              0         0            0      0   \n",
      "26         1          0              0         0            0      1   \n",
      "27         0          0              0         0            0      1   \n",
      "28         0          0              0         0            1      0   \n",
      "29         1          0              0         0            0      0   \n",
      "..       ...        ...            ...       ...          ...    ...   \n",
      "87         0          0              0         0            0      0   \n",
      "88         0          0              0         0            0      0   \n",
      "89         0          0              0         0            0      0   \n",
      "90         0          0              0         0            0      0   \n",
      "91         0          0              0         0            1      0   \n",
      "92         1          0              0         0            0      0   \n",
      "93         0          0              0         0            1      0   \n",
      "94         1          0              0         0            0      1   \n",
      "95         0          0              0         0            0      0   \n",
      "96         0          0              0         0            0      0   \n",
      "97         0          0              0         0            0      0   \n",
      "98         0          0              0         0            0      0   \n",
      "99         0          0              0         0            0      0   \n",
      "100        0          0              0         0            0      0   \n",
      "101        0          0              0         0            0      0   \n",
      "102        0          0              0         0            0      0   \n",
      "103        0          0              0         0            0      1   \n",
      "104        0          0              0         0            0      0   \n",
      "105        0          0              0         0            0      0   \n",
      "106        0          0              0         0            0      0   \n",
      "107        0          0              0         0            0      0   \n",
      "108        0          0              0         0            0      0   \n",
      "109        0          0              0         0            0      0   \n",
      "110        0          0              0         0            0      0   \n",
      "111        0          0              0         0            0      0   \n",
      "112        0          0              0         0            0      0   \n",
      "113        0          0              0         0            0      0   \n",
      "114        0          0              0         0            0      1   \n",
      "115        0          0              0         0            0      0   \n",
      "116        0          0              0         0            0      1   \n",
      "\n",
      "     abovenamed  ache  achieve  aching ...   working  workup  would  wound  \\\n",
      "0             0     0        0       0 ...         0       0      0      0   \n",
      "1             0     0        0       0 ...         0       0      0      0   \n",
      "2             0     0        0       0 ...         0       0      0      0   \n",
      "3             0     0        0       0 ...         0       0      0      0   \n",
      "4             0     0        0       0 ...         0       0      0      0   \n",
      "5             0     0        0       0 ...         0       0      0      0   \n",
      "6             0     0        0       0 ...         0       0      1      0   \n",
      "7             0     0        0       0 ...         0       0      0      0   \n",
      "8             0     0        0       0 ...         0       0      0      0   \n",
      "9             0     0        0       0 ...         0       0      1      0   \n",
      "10            0     0        0       0 ...         0       0      0      0   \n",
      "11            0     0        0       0 ...         0       0      0      0   \n",
      "12            0     0        0       0 ...         0       0      0      0   \n",
      "13            0     0        0       0 ...         0       0      0      0   \n",
      "14            0     0        0       0 ...         0       0      1      0   \n",
      "15            0     0        0       0 ...         0       0      2      0   \n",
      "16            0     0        0       0 ...         0       0      0      0   \n",
      "17            0     0        0       0 ...         0       0      2      0   \n",
      "18            0     0        0       0 ...         0       0      3      0   \n",
      "19            0     0        0       0 ...         0       0      1      0   \n",
      "20            0     0        0       0 ...         0       0      0      0   \n",
      "21            0     0        0       0 ...         0       0      0      2   \n",
      "22            0     1        0       0 ...         0       0      1      0   \n",
      "23            0     0        0       0 ...         0       0      0      0   \n",
      "24            0     0        0       0 ...         0       0      0      1   \n",
      "25            0     0        0       0 ...         0       0      0      0   \n",
      "26            0     0        0       0 ...         0       0      0      0   \n",
      "27            0     0        0       0 ...         0       0      0      0   \n",
      "28            0     0        0       0 ...         0       0      0      0   \n",
      "29            0     0        0       0 ...         0       0      0      0   \n",
      "..          ...   ...      ...     ... ...       ...     ...    ...    ...   \n",
      "87            0     0        0       0 ...         0       0      0      0   \n",
      "88            0     0        0       0 ...         0       0      1      0   \n",
      "89            0     0        0       0 ...         0       0      4      0   \n",
      "90            0     0        0       0 ...         1       0      0      0   \n",
      "91            0     0        0       0 ...         0       0      3      0   \n",
      "92            0     0        0       0 ...         0       0      0      0   \n",
      "93            0     0        0       0 ...         0       0      0      0   \n",
      "94            0     0        0       0 ...         0       0      2      0   \n",
      "95            0     0        0       0 ...         0       0      0      0   \n",
      "96            0     0        0       0 ...         0       0      0      0   \n",
      "97            0     0        0       0 ...         0       0      0      0   \n",
      "98            0     0        0       0 ...         0       0      0      0   \n",
      "99            1     0        0       0 ...         0       0      2      0   \n",
      "100           0     0        0       0 ...         0       0      1      0   \n",
      "101           0     0        0       0 ...         0       0      1      0   \n",
      "102           0     0        0       0 ...         0       0      1      0   \n",
      "103           0     0        0       0 ...         0       0      1      0   \n",
      "104           0     0        0       0 ...         0       0      0      0   \n",
      "105           0     0        0       0 ...         0       0      0      0   \n",
      "106           0     0        0       0 ...         0       0      0      0   \n",
      "107           0     0        0       0 ...         0       0      2      0   \n",
      "108           0     0        0       0 ...         0       0      2      0   \n",
      "109           0     0        0       0 ...         0       0      0      0   \n",
      "110           0     1        0       0 ...         0       0      0      0   \n",
      "111           0     0        0       0 ...         0       0      0      0   \n",
      "112           0     0        0       0 ...         0       0      0      0   \n",
      "113           0     0        0       0 ...         0       0      0      0   \n",
      "114           0     0        0       0 ...         0       0      0      0   \n",
      "115           0     0        0       0 ...         0       0      0      0   \n",
      "116           0     0        0       0 ...         0       0      0      0   \n",
      "\n",
      "     write  writing  year  you  Surgery - Yes OR No  Age  \n",
      "0        1        0     0    0                    Y   67  \n",
      "1        0        0     0    0                    Y   67  \n",
      "2        0        0     0    0                    N   67  \n",
      "3        0        0     0    0                    N   81  \n",
      "4        0        1     0    0                    Y   81  \n",
      "5        1        0     0    0                    Y   81  \n",
      "6        0        0     0    0                    Y   81  \n",
      "7        0        0     0    0                    Y   81  \n",
      "8        0        0     1    0                    N  100  \n",
      "9        0        0     0    0                    Y  100  \n",
      "10       0        0     0    0                    N  100  \n",
      "11       0        0     1    0                    N  100  \n",
      "12       0        0     0    0                    N  100  \n",
      "13       1        0     0    0                    N  100  \n",
      "14       0        0     0    0                    Y  100  \n",
      "15       0        0     0    0                    Y  100  \n",
      "16       1        0     0    0                    Y   59  \n",
      "17       0        0     1    0                    Y   59  \n",
      "18       0        0     0    0                    Y   59  \n",
      "19       0        0     0    0                    N   59  \n",
      "20       1        1     0    0                    Y   59  \n",
      "21       1        0     0    0                    Y   59  \n",
      "22       0        0     0    0                    Y   59  \n",
      "23       1        0     0    0                    Y   59  \n",
      "24       1        0     0    1                    Y   59  \n",
      "25       1        0     1    0                    Y   59  \n",
      "26       0        0     0    0                    Y   59  \n",
      "27       0        0     0    0                    Y   59  \n",
      "28       0        0     0    0                    Y   59  \n",
      "29       0        0     1    0                    Y   59  \n",
      "..     ...      ...   ...  ...                  ...  ...  \n",
      "87       0        0     0    0                    Y   81  \n",
      "88       0        0     0    0                    N   65  \n",
      "89       0        0     1    0                    Y   65  \n",
      "90       0        0     0    0                    Y   58  \n",
      "91       0        0     0    0                    Y   58  \n",
      "92       1        0     2    1                    N   55  \n",
      "93       0        0     0    0                    N   55  \n",
      "94       0        0     0    0                    Y   67  \n",
      "95       0        0     0    0                    Y   67  \n",
      "96       0        1     0    0                    Y   67  \n",
      "97       1        0     0    0                    Y   67  \n",
      "98       1        0     0    0                    Y   67  \n",
      "99       0        1     0    0                    Y   67  \n",
      "100      2        0     0    0                    Y   67  \n",
      "101      0        0     0    0                    Y   67  \n",
      "102      0        0     0    0                    Y   67  \n",
      "103      1        0     0    0                    Y   67  \n",
      "104      1        0     1    0                    Y   67  \n",
      "105      0        1     0    0                    Y   67  \n",
      "106      0        0     0    0                    Y   67  \n",
      "107      0        0     0    0                    Y   67  \n",
      "108      0        0     0    0                    Y   67  \n",
      "109      0        0     0    0                    Y   67  \n",
      "110      1        0     0    0                    Y   67  \n",
      "111      0        0     0    0                    Y   67  \n",
      "112      1        0     0    0                    Y   67  \n",
      "113      1        0     0    0                    N   67  \n",
      "114      0        0     0    0                    Y   67  \n",
      "115      1        0     0    0                    Y   67  \n",
      "116      0        0     0    0                    Y   67  \n",
      "\n",
      "[117 rows x 1002 columns]\n"
     ]
    }
   ],
   "source": [
    "# extracting the features and storing it in a different dataset\n",
    "featureset = pd.DataFrame(dense,columns=bow.get_feature_names())\n",
    "featureset[\"Surgery - Yes OR No\"] = dataset['Surgery - Yes OR No']\n",
    "classlabel = \"Surgery - Yes OR No\"\n",
    "featureset[\"Age\"]=dataset[\"Age\"]\n",
    "\n",
    "print(featureset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 1002)\n"
     ]
    }
   ],
   "source": [
    "# shuffing the data to avoid baising \n",
    "import numpy as np\n",
    "featureset = featureset.sample(frac = 1)\n",
    "print(featureset.shape)\n",
    "Targetindex = featureset.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test split out of training (Divided training into test and train sets respectively)\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def splitter(trials,data,size):\n",
    "    \n",
    "    model_acc=[]\n",
    "    model_f1=[]\n",
    "    model_recall=[]\n",
    "    model_precision=[]\n",
    "    \n",
    "  \n",
    "    for i in range(0,trials):\n",
    "        dataset_train, dataset_test = train_test_split(data, test_size=size)\n",
    "        dataset_train = pd.DataFrame(dataset_train)\n",
    "        dataset_test = pd.DataFrame(dataset_test)\n",
    "        dataset_train.columns = featureset.columns\n",
    "        dataset_test.columns = featureset.columns\n",
    "        Targetindex = dataset_train.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "        \n",
    "        X = dataset_train.drop(dataset_train.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y = dataset_train[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        X1 = dataset_test.drop(dataset_test.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y1 = dataset_test[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        \n",
    "        # label encode the target variable \n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        #print(y)\n",
    "        train_y = encoder.fit_transform(y)\n",
    "        #print(train_y)\n",
    "        valid_y = encoder.fit_transform(y1)\n",
    "        \n",
    "        clf = linear_model.LogisticRegression().fit(X, train_y)\n",
    "        \n",
    "        testpred = clf.predict(X1)\n",
    "        print(clf.coef_.shape)\n",
    "        model_acc.append(accuracy_score(valid_y,testpred))\n",
    "        model_f1.append(f1_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_recall.append(recall_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_precision.append(precision_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        \n",
    "        matrix=confusion_matrix(valid_y,testpred)\n",
    "        print(\"Confusion matrix for split\",i)\n",
    "        print(matrix)\n",
    "        \n",
    "    print(\"Average metrics for Logistic Regression are:\")\n",
    "    \n",
    "    acc_avg=Average(model_acc)\n",
    "    f1_avg=Average(model_f1)\n",
    "    recall_avg=Average(model_recall)\n",
    "    precision_avg=Average(model_precision)\n",
    "\n",
    "    return acc_avg,f1_avg,recall_avg,precision_avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1001)\n",
      "Confusion matrix for split 0\n",
      "[[ 0  2]\n",
      " [ 1 33]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 1\n",
      "[[ 2  1]\n",
      " [ 0 33]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 2\n",
      "[[ 2  1]\n",
      " [ 2 31]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 3\n",
      "[[ 1  2]\n",
      " [ 1 32]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 4\n",
      "[[ 2  2]\n",
      " [ 1 31]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 5\n",
      "[[ 2  6]\n",
      " [ 0 28]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 6\n",
      "[[ 2  4]\n",
      " [ 0 30]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 7\n",
      "[[ 0  6]\n",
      " [ 1 29]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 8\n",
      "[[ 1  7]\n",
      " [ 0 28]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 9\n",
      "[[ 2  3]\n",
      " [ 0 31]]\n",
      "Average metrics for Logistic Regression are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8888888888888887,\n",
       " 0.9380281095779777,\n",
       " 0.9815095811051695,\n",
       " 0.9008984275528393)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter(10,np.array(featureset),0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words Model using L1 and L2 Regularization\n",
    "#Test split out of training (Divided training into test and train sets respectively)\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def splitter1(trials,data,size):\n",
    "    \n",
    "    model_acc=[]\n",
    "    model_f1=[]\n",
    "    model_recall=[]\n",
    "    model_precision=[]\n",
    "    \n",
    "  \n",
    "    for i in range(0,trials):\n",
    "        dataset_train, dataset_test = train_test_split(data, test_size=size)\n",
    "        dataset_train = pd.DataFrame(dataset_train)\n",
    "        dataset_test = pd.DataFrame(dataset_test)\n",
    "        dataset_train.columns = featureset.columns\n",
    "        dataset_test.columns = featureset.columns\n",
    "        Targetindex = dataset_train.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "        \n",
    "        X = dataset_train.drop(dataset_train.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y = dataset_train[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        X1 = dataset_test.drop(dataset_test.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y1 = dataset_test[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        \n",
    "        # label encode the target variable \n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        #print(y)\n",
    "        train_y = encoder.fit_transform(y)\n",
    "        #print(train_y)\n",
    "        valid_y = encoder.fit_transform(y1)\n",
    "        #Regularization penalty\n",
    "        clf = linear_model.LogisticRegression(penalty='l2', tol=1e-6,C=100).fit(X, train_y)\n",
    "        \n",
    "        testpred = clf.predict(X1)\n",
    "        print(clf.coef_.shape)\n",
    "        model_acc.append(accuracy_score(valid_y,testpred))\n",
    "        model_f1.append(f1_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_recall.append(recall_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_precision.append(precision_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        \n",
    "        matrix=confusion_matrix(valid_y,testpred)\n",
    "        print(\"Confusion matrix for split\",i)\n",
    "        print(matrix)\n",
    "        \n",
    "    print(\"Average metrics for Logistic Regression are:\")\n",
    "    \n",
    "    acc_avg=Average(model_acc)\n",
    "    f1_avg=Average(model_f1)\n",
    "    recall_avg=Average(model_recall)\n",
    "    precision_avg=Average(model_precision)\n",
    "\n",
    "    return acc_avg,f1_avg,recall_avg,precision_avg\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1001)\n",
      "Confusion matrix for split 0\n",
      "[[ 1  2]\n",
      " [ 3 30]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 1\n",
      "[[ 0  8]\n",
      " [ 0 28]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 2\n",
      "[[ 1  3]\n",
      " [ 0 32]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 3\n",
      "[[ 2  2]\n",
      " [ 0 32]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 4\n",
      "[[ 1  3]\n",
      " [ 1 31]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 5\n",
      "[[ 1  4]\n",
      " [ 0 31]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 6\n",
      "[[ 0  4]\n",
      " [ 2 30]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 7\n",
      "[[ 2  7]\n",
      " [ 0 27]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 8\n",
      "[[ 2  7]\n",
      " [ 1 26]]\n",
      "(1, 1001)\n",
      "Confusion matrix for split 9\n",
      "[[ 2  2]\n",
      " [ 1 31]]\n",
      "Average metrics for Logistic Regression are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.861111111111111, 0.9216635283401861, 0.9747053872053872, 0.8771962269756388)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter1(10,np.array(featureset),0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "(1, 1001)\n",
      "[[0 2]\n",
      " [1 9]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  24  25  26  27  28  29\n",
      "  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [12 13 14 15 16 17 18 19 20 21 22 23]\n",
      "(1, 1001)\n",
      "[[2 1]\n",
      " [0 9]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  36  37  38  39  40  41  42  43  44  45  46  47\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "(1, 1001)\n",
      "[[ 1  1]\n",
      " [ 0 10]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [36 37 38 39 40 41 42 43 44 45 46 47]\n",
      "(1, 1001)\n",
      "[[ 0  1]\n",
      " [ 1 10]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  60  61  62  63  64  65\n",
      "  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [48 49 50 51 52 53 54 55 56 57 58 59]\n",
      "(1, 1001)\n",
      "[[ 0  1]\n",
      " [ 0 11]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  72  73  74  75  76  77  78  79  80  81  82  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [60 61 62 63 64 65 66 67 68 69 70 71]\n",
      "(1, 1001)\n",
      "[[ 0  2]\n",
      " [ 0 10]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [72 73 74 75 76 77 78 79 80 81 82 83]\n",
      "(1, 1001)\n",
      "[[0 2]\n",
      " [1 9]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  95  96  97  98  99 100\n",
      " 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116] TEST: [84 85 86 87 88 89 90 91 92 93 94]\n",
      "(1, 1001)\n",
      "[[ 1  0]\n",
      " [ 0 10]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94 106 107 108 109 110 111 112 113 114 115 116] TEST: [ 95  96  97  98  99 100 101 102 103 104 105]\n",
      "(1, 1001)\n",
      "[[ 1 10]\n",
      " [ 0  0]]\n",
      "TRAIN: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105] TEST: [106 107 108 109 110 111 112 113 114 115 116]\n",
      "(1, 1001)\n",
      "[[1 3]\n",
      " [0 7]]\n",
      "Average metrics for Logistic Regression are:\n",
      "0.7734848484848484\n",
      "0.8212268056796258\n",
      "0.8709090909090909\n",
      "0.7804545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data =np.array(featureset)\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=None, shuffle=False)\n",
    "model_acc=[]\n",
    "model_f1=[]\n",
    "model_recall=[]\n",
    "model_precision=[]\n",
    "for train_index, test_index in kf.split(data):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    data_train, data_test = data[train_index], data[test_index]\n",
    "    data_train = pd.DataFrame(data_train)\n",
    "    data_test = pd.DataFrame(data_test)\n",
    "    data_train.columns = featureset.columns\n",
    "    data_test.columns = featureset.columns\n",
    "    Targetindex = data_train.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "    X =data_train.drop(data_train.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "    y = data_train[\"Surgery - Yes OR No\"] # only the target variable\n",
    "    X1 = data_test.drop(data_test.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "    y1 = data_test[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        \n",
    "    # label encode the target variable \n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    #print(y)\n",
    "    train_y = encoder.fit_transform(y)\n",
    "    #print(train_y)\n",
    "    valid_y = encoder.fit_transform(y1)\n",
    "    #Regularization penalty\n",
    "    clf = linear_model.LogisticRegression(penalty='l2', tol=1e-6,C=100).fit(X, train_y)\n",
    "        \n",
    "    testpred = clf.predict(X1)\n",
    "    print(clf.coef_.shape)\n",
    "    model_acc.append(accuracy_score(valid_y,testpred))\n",
    "    model_f1.append(f1_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "    model_recall.append(recall_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "    model_precision.append(precision_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        \n",
    "    matrix=confusion_matrix(valid_y,testpred)\n",
    "    \n",
    "    print(matrix)\n",
    "        \n",
    "    \n",
    "    \n",
    "acc_avg=Average(model_acc)\n",
    "f1_avg=Average(model_f1)\n",
    "recall_avg=Average(model_recall)\n",
    "precision_avg=Average(model_precision)\n",
    "print(\"Average metrics for Logistic Regression are:\")\n",
    "print(acc_avg)\n",
    "print(f1_avg)\n",
    "print(recall_avg)\n",
    "print(precision_avg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
