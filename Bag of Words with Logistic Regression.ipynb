{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nikhil\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Case', 'Age', 'Text Details', 'Surgery - Yes OR No',\n",
       "       'word_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pwd\n",
    "dataset = pd.read_csv('/Users/nikhil/pre_processed_patient_diagnostics.csv', encoding='ISO-8859-1');\n",
    "\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['Surgery - Yes OR No'] = dataset['Surgery - Yes OR No'].astype(str) # taking the target column in seperate variable. we will add this to final data frame when pre processing is done\n",
    "data_desc = dataset[\"Text Details\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(data_desc)):\n",
    "    data_desc[i] = re.sub(\" \\d+\", \" \",data_desc[i]) # this will retain only the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "data_mat = bow.fit_transform(data_desc)\n",
    "dense = data_mat.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 1001)\n"
     ]
    }
   ],
   "source": [
    "# extracting the features and storing it in a different dataset\n",
    "featureset = pd.DataFrame(dense,columns=bow.get_feature_names())\n",
    "featureset[\"Surgery - Yes OR No\"] = dataset['Surgery - Yes OR No']\n",
    "classlabel = \"Surgery - Yes OR No\"\n",
    "\n",
    "\n",
    "print(featureset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117, 1001)\n"
     ]
    }
   ],
   "source": [
    "# shuffing the data to avoid baising \n",
    "import numpy as np\n",
    "featureset = featureset.sample(frac = 1)\n",
    "print(featureset.shape)\n",
    "Targetindex = featureset.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test split out of training (Divided training into test and train sets respectively)\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def splitter(trials,data,size):\n",
    "    \n",
    "    model_acc=[]\n",
    "    model_f1=[]\n",
    "    model_recall=[]\n",
    "    model_precision=[]\n",
    "    \n",
    "  \n",
    "    for i in range(0,trials):\n",
    "        dataset_train, dataset_test = train_test_split(data, test_size=size)\n",
    "        dataset_train = pd.DataFrame(dataset_train)\n",
    "        dataset_test = pd.DataFrame(dataset_test)\n",
    "        dataset_train.columns = featureset.columns\n",
    "        dataset_test.columns = featureset.columns\n",
    "        Targetindex = dataset_train.columns.get_loc(\"Surgery - Yes OR No\")\n",
    "        \n",
    "        X = dataset_train.drop(dataset_train.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y = dataset_train[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        X1 = dataset_test.drop(dataset_test.columns[[Targetindex]], axis=1) # all the features except the target variable\n",
    "        y1 = dataset_test[\"Surgery - Yes OR No\"] # only the target variable\n",
    "        \n",
    "        # label encode the target variable \n",
    "        encoder = preprocessing.LabelEncoder()\n",
    "        train_y = encoder.fit_transform(y)\n",
    "        valid_y = encoder.fit_transform(y1)\n",
    "        \n",
    "        clf = linear_model.LogisticRegression().fit(X, train_y)\n",
    "        \n",
    "        testpred = clf.predict(X1)\n",
    "        \n",
    "        model_acc.append(accuracy_score(valid_y,testpred))\n",
    "        model_f1.append(f1_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_recall.append(recall_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        model_precision.append(precision_score(valid_y,testpred,pos_label=1,average=\"binary\"))\n",
    "        \n",
    "        matrix=confusion_matrix(valid_y,testpred)\n",
    "        print(\"Confusion matrix for split\",i)\n",
    "        print(matrix)\n",
    "        \n",
    "    print(\"Average metrics for Logistic Regression are:\")\n",
    "    \n",
    "    acc_avg=Average(model_acc)\n",
    "    f1_avg=Average(model_f1)\n",
    "    recall_avg=Average(model_recall)\n",
    "    precision_avg=Average(model_precision)\n",
    "\n",
    "    return acc_avg,f1_avg,recall_avg,precision_avg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for split 0\n",
      "[[ 3  1]\n",
      " [ 0 32]]\n",
      "Confusion matrix for split 1\n",
      "[[ 2  6]\n",
      " [ 0 28]]\n",
      "Confusion matrix for split 2\n",
      "[[ 1  3]\n",
      " [ 0 32]]\n",
      "Confusion matrix for split 3\n",
      "[[ 3  2]\n",
      " [ 1 30]]\n",
      "Confusion matrix for split 4\n",
      "[[ 5  0]\n",
      " [ 0 31]]\n",
      "Confusion matrix for split 5\n",
      "[[ 3  4]\n",
      " [ 2 27]]\n",
      "Confusion matrix for split 6\n",
      "[[ 0  7]\n",
      " [ 0 29]]\n",
      "Confusion matrix for split 7\n",
      "[[ 1  3]\n",
      " [ 1 31]]\n",
      "Confusion matrix for split 8\n",
      "[[ 2  7]\n",
      " [ 1 26]]\n",
      "Confusion matrix for split 9\n",
      "[[ 2  6]\n",
      " [ 0 28]]\n",
      "Average metrics for Logistic Regression are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8777777777777777,\n",
       " 0.9297040128864877,\n",
       " 0.9830489381205455,\n",
       " 0.8844708298764277)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter(10,np.array(featureset),0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
